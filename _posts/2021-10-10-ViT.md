---
layout: post
title: Vision Transformer
category: Computer Vision
tag: ViT
---

* 자연어 처리에서 많은 성능을 가져온 Transformer로 RNN을 구축하듯, Computer vision 분야에서는 CNN을 대신하도록 적용됨.

* 다양한 데이터셋(ImageNet, CIFAR, VTAB)에 대하여 sota급의 성능을 달성함과동시에 BiT나 NoisyStudent와 비교하여 computation load를 $\frac{1}{15}$로 줄임.

* 하나의 Image를 patch로 나누어 단어와 자연어 처리의 단어처럼 구분
* Transformer의 encoder로 네트워크를 구성
* JFT-300M으로 사전학습함
    ```
    JFT-300M is an internal Google dataset used for training image classification models. Images are labeled using an algorithm that uses complex mixture of raw web signals, connections between web-pages and user feedback. This results in over one billion labels for the 300M images (a single image can have multiple labels). Of the billion image labels, approximately 375M are selected via an algorithm that aims to maximize label precision of selected images.
    ```

    > 이렇게 큰 데이터셋에 대해서 학습을 미리 해놓으니까 잘 된거 아닐까.....? ㅜ.ㅜ



