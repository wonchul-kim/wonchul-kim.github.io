# Bird's Eye View (BEV)

#### 자율주행에서 **BEV**가 중요한 이유

1. 통합된 360도 환경 인식
2. `occlusion` 문제 해결
3. 정확한 공간적 관계 표현
  - **BEV** coordinate system에서는 각 격자 셀이 실제 세계의 측정값(예: 1미터)에 대응되어,
  - 객체 간의 거리와 위치 관계를 정확하게 나타낼 수 있습니다.
  - **BEV** coordinate는 격자 시스템으로 각 격자의 크기가 모두 동일함
4. 다양한 작업의 통합 플랫폼
  - **BEV** representation을 통해 3D 객체 탐지, 맵 분할, 궤적 예측, 경로 계획 등 자율주행에 필요한 모든 작업을 하나의 통일된 공간에서 수행 가능

#### BEV Transformation
1. multi-camera input
2. depth estimation
  - 카메라 이미지들은 2D정보이고, depth를 사용하여 3D 공간으로 변환
  - 이는 monocular depth estimation 기술을 이용할 수 있음
3. 3D feature lifting
  - 추정된 depth를 바탕으로 2D 이미지 feature를 3D 공간으로 변환
  - 카메라의 intrinsic 및 extrinsic 파라미터가 사용됨
4. BEV projection
  - 3D 공간의 feature들을 **BEV** 평면으로 투영
  - `z`축의 정보는 일반적으로 생략됨


### Methods

#### 초기 방법: IPM (Inverse Perspective Mapping)
가장 기본적인 BEV 변환 방법은 IPM으로, 평평한 지면을 가정하고 호모그래피 변환을 사용합니다. 
하지만 이 방법은 실제 도로의 복잡한 지형을 제대로 반영하지 못하는 한계가 있습니다.

#### 딥러닝 기반 방법들

* 명시적 변환 (Explicit Transformation)
  - 2D-3D 방법: 깊이 추정을 통해 2D 이미지를 3D로 변환 후 BEV 투영
  - 3D-2D 방법: 3D 공간에서 직접 BEV로 투영

* 암시적 변환 (Implicit Transformation)
  - Transformer 기반: BEVFormer와 같은 attention 메커니즘 활용
  - MLP 기반: 다층 퍼셉트론을 통한 특징 변환

#### BEV의 응용 분야

1. 3D Object Detection

BEV 공간에서 차량, 보행자, 자전거 등의 3D 경계 상자를 예측합니다. 이는 객체의 정확한 위치, 크기, 방향을 파악하는 데 핵심적입니다.

2. Map Segmentation

도로, 인도, 차선 등 주행 환경의 각 영역을 의미적으로 분할합니다. 이는 주행 가능 영역과 불가능 영역을 구분하는 데 중요합니다.

3. Motion Prediction

다른 차량이나 보행자의 미래 궤적을 예측합니다. BEV에서는 모든 동적 객체들의 상대적 움직임을 일관된 좌표계에서 추적할 수 있습니다.

4. Occupancy Prediction

3D 공간의 각 복셀(voxel)이 점유되어 있는지를 예측합니다. 이는 미래의 주행 경로를 안전하게 계획하는 데 필수적입니다.

5. 시간적 정보 융합 (Temporal Fusion)
실제 자율주행에서는 단일 프레임만으로는 완전한 환경 인식이 어렵습니다. 따라서 과거 프레임들의 정보를 현재와 융합하는 시간적 융합이 중요합니다:

6. 병렬 융합 (Parallel Fusion)
고정된 윈도우 크기 내의 모든 과거 프레임을 동시에 처리합니다. 효과적이지만 메모리와 계산량이 많이 필요합니다.

7. 순환 융합 (Recurrent Fusion)
과거 정보를 하나의 메모리 특징으로 인코딩하여 효율적으로 처리합니다. 계산량은 적지만 장기간 정보 활용에 한계가 있습니다.




## References
- https://www.cyient.com/blog/birds-eye-view-bev-implementation-a-comprehensive-guide
- 
