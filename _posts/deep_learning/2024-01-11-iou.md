---
layout: post
title: IoUs
category: Deep Learning
tag: [iou, matrix]
---

## IoU

먼저, **IoU**를 사용하는 이유는 예측한 `bounding box`와 `ground truth`의 위치뿐만 아니라 크기에 대한 차이점도 어느 정도 포함하기 위해서다. 

<img src='/assets/computer_vision/papers/iou/iou_reason.png'>

예를 들어, **MSE (L2 Loss)**로 좌표간의 거리에 대해서만 계산을 하면, 객체가 큰 경우와 작은 경우에 대한 값이 동일하지만, **IoU**를 사용하게 되면 다르다. 

즉, 위치와 크기에 대해서 동시에 반영을 할 수 있기 때문에 `object detection`에서 단순히 좌표간의 **MSE**를 구하는 것보다는 **IoU**를 활용하는 것이 더 낫다.


일반적인 `IoU`는 위와 같이 예측한 `bouding box`와 `ground truth`에 대한 교집합과 합집합으로  다음과 같이 계산한다. 

<img src='/assets/computer_vision/papers/iou/iou.png'>

----------------------------------------------
## [GIoU (Generaized IoU)](https://arxiv.org/abs/1902.09630)

- **IoU**의 문제점 1
  일반적으로 **IoU**는 `object detection`에서 평가지표로는 사용하지만, loss function에는 사용하지 않는다. 그렇기 때문에 실질적으로 `l1 loss`만으로는 아래와 같이 **IoU**를 1로 만들기는 힘들다고 할 수 있다. 

  - `l2 loss`에 따른 **IoU**의 필요성 
  <img src='/assets/computer_vision/papers/iou/giou_a.png'>

  - `l1 loss`에 따른 **IoU**의 필요성
  <img src='/assets/computer_vision/papers/iou/giou_b.png'>

  위와 같이 **IoU**는 근본적으로 예측한 `bounding box`에 따라서 `l1 loss`과 `l2 loss`는 동일하지만, **IoU**는 다르다는 것을 통해서 `object detection`에서의 최종 목표인 **IoU**를 1로 만드는 것과는 목적과 방법이 맞지 않는다.

- **IoU**의 문제점 2
  객체의 크기에 따라 **IoU**는 범위가 달라진다. 예를 들어, 큰 객체에 대해서는 큰 loss를 가지고, 작은 객체에 대해서는 작은 loss를 가질 수밖에 없다. 따라서, **GIoU**는 **scale-invariant**하다는 특징을 갖는다.

이를 위해서 **GIoU**는 **IoU**를 loss function에 직접적으로 사용하기 위한 방법을 제시한다.

**IoU**가 loss function에 직접적으로 사용되지 못한 이유는, 예측한 `bouding boxx`와 `ground truth`의 교집합이 없을 경우 어느 정도의 오차가 있는지 모르는데 `loss (= 1 - IoU)`는 지속적으로 1이 될 것이기 때문에 `gradient vanishing` 또는 학습에 악영향을 미치기 때문이다. 

그렇기 때문에 **GIoU**는 교집합이 존재하지 않더라도 거리에 따른 오차를 포함시킬 수 있는 방법을 다음과 같이 예측한 `bouding box`와 `ground truth`를 모두 포함하는 box를 만들어서 해결하고자 한다.

<img src='/assets/computer_vision/papers/iou/giou.png'>

하지만, 예측한 `bouding box`가 `ground truth`를 포함해 버리는 경우, **IoU**와 **GIoU**는 일정한 값을 가지게 되어 문제가 생긴다. 

> 특히, 수렴속도가 느리고, 부정확하게 박스를 예측한다는 문제점이 존재한다고 한다???

----------------------------------------------
## [DIoU (Distance IoU)](https://arxiv.org/abs/1911.08287)

<img src='/assets/computer_vision/papers/iou/diou_reason.png'>

위의 사진에서 볼 수 있듯이, 예측한 `bouding box`가 `ground truth`를 포함해 버리는 경우, **IoU**와 **GIoU**는 일정한 값을 가지게 되어 문제가 생긴다. 그렇기 때문에 각 box의 중심좌표를 loss에 포함시키는 방식을 제안한다. 

$$
L_{DIoU} = 1 - IoU + \frac{\rho^2(\mathbf{b}, \mathbf{b}^{gt})}{c^2}
$$

- $\rho$: Euclidean distance
- $\mathbf{b}$: `bounding box`의 중심좌표
- $\mathbf{b}^{gt}$: `ground truth`의 중심좌표
- $c$: `bounding box`와 `ground truth`를 포함하는 최소 박스($C$)의 대각선 길이

> **GIoU**의 문제점이었던 수렴속도와 정확도가 개선되었고, 특히 `NMS` 적용시에 `ground truth`가 서로 겹쳐있는 `cluttered object`에 대해서 더 강건하다고 한다!


----------------------------------------------
## [CIoU (Complete IoU)](https://arxiv.org/abs/1911.08287)

**DIoU**를 제안한 논문에서는 **CIoU**도 제안하였는데, `bounding box` 예측에는 `overlap area`, `central point distance`, `aspect ratio`의 3가지 요소를 고려하는 것이 좋다고 한다. `overlap area`, `central point distance`는 이미 **DIoU**에 포함되어 있고, 추가적으로 `aspect ratio`를 도입하여 다음과 같은 수식을 제안한다. 

$$
L_{CIoU} = 1 - IoU + \frac{\rho^2(\mathbf{b}, \mathbf{b}^{gt})}{c^2} + \alpha{v}
$$
$$
v = \frac{4}{\pi^2}(arctan{\frac{w^{gt}}{h^{gt}}} - arctan{\frac{w}{h}})^2, 
\alpha = \frac{v}{(1 - IoU) + v}
$$

- $v$: 두 box의 가로/세로 비율에 대한 연속성(?)을 측정
- $\alpha$: positive trade-off parameter로 겹치는 영역이 값이 높은 우선순위를 갖도록 하여 겹치는 경우와 겹치지 않는 경우에 대한 균형을 조절한다.


이는 기존의 cluttered objects에 대해서 `NMS`를 진행할 때, occlusion으로 인해서 제대로 예측한 `bounding box`가 사라지는 문제를 해결하는 데에도 도움이 된다. 

$$
s_i =
    \begin{cases}
      s_i & IoU - R_{DIoU}(M, B_i) \lt \epsilon\\
      0 & IoU - R_{DIoU}(M, B_i) \geq \epsilon
    \end{cases} 
$$

- $\epsilon$: threshold
- $s_i$: score

> 중심 거리가 멀면서 `IoU`가 큰 경우에는 다른 물체를 감지하였을 가능ㅎ성이 있기 때문에 삭제하지 않는다.


- **IoU**가 0.5 미만인 경우, **CIoU** == **DIoU**
- **IoU**가 0.5 이상인 경우, **IoU**가 커질수록 $v$의 영향이 커져 **IoU**가 1에 빨리 접근할 수 있또록 도와준다.

## References:

- [Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression
](https://arxiv.org/abs/1902.09630)

- [Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression](https://arxiv.org/abs/1911.08287)