---
layout: post
title: Papers To Read
category: Deep Learning
tag: [papers to read]
---

# Papers To Read

----------------------------------------------------------------------------
## Computer Vision

|    | papers | code |
|:--:|:-------|:---:|
| ✅ | [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) | [github]() |
|  | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) | [github]() |
|  | [Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection](https://arxiv.org/abs/2205.09613) | [github]() |
|  | [HiViT: Hierarchical Vision Transformer Meets Masked Image Modeling](https://arxiv.org/abs/2205.14949) | [github]() |
|  | [From SAM to CAMs: Exploring Segment Anything Model for Weakly Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2024/papers/Kweon_From_SAM_to_CAMs_Exploring_Segment_Anything_Model_for_Weakly_CVPR_2024_paper.pdf) | [github](https://github.com/sangrockEG/S2C) |
|  |  | [github]() |
|  |  | [github]() |


#### Classification

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### HBB Object Detection

|    | papers | code |
|:--:|:-------|:---:|
| ✅ | [YOLOv10: Real-Time End-to-End Object Detection](https://arxiv.org/abs/2405.14458) | [github](https://github.com/THU-MIG/yolov10) |
|  | [DETRs Beat YOLOs on Real-time Object Detection](https://arxiv.org/abs/2304.08069) | [github](https://github.com/lyuwenyu/RT-DETR) |
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### OBB Object Detection

|    | papers | code |
|:--:|:-------|:---:|
|  | [Spatial Transform Decoupling for Oriented Object Detection](https://arxiv.org/html/2308.10561v2) | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### Semantic Segmentation

|    | papers | code |
|:--:|:-------|:---:|
|  | [SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks](https://arxiv.org/abs/2401.15741) | [github](https://github.com/serdarch/sernet-former) |
|  | [Open-World Semantic Segmentation Including Class Similarity](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/sodano2024cvpr.pdf) | [github]() |
|  |  | [github]() |

#### Instance Segmentation

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Language Model

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Multi-Modal

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Transfer Learning

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Multi-modal

|    | papers | code |
|:--:|:-------|:---:|
| ✅ | [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) | [github]() |
|  |  | [github]() |
|  |  | [github]() |


 
## Transformer
|    | papers | code |
|:--:|:-------|:---:|
|  | [Vision Transformer Adapter for Dense Predictions](https://arxiv.org/abs/2205.08534) | [github](https://github.com/czczup/vit-adapter) |
|  | [ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions](https://arxiv.org/abs/2403.07392) | [github](https://github.com/Traffic-X/ViT-CoMer) |
|  | [DIFFERENTIAL TRANSFORMER](https://arxiv.org/pdf/2410.05258) | [github]() |
|  | [SELECTIVE ATTENTION IMPROVES TRANSFORMER](https:/arxiv.org/pdf/2410.02703v1) | [github]() |
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |


## LLM

- [LLMs from scratch](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material)