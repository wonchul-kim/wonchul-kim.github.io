---
layout: post
title: Papers To Read
category: Deep Learning
tag: [papers to read]
---

# Papers To Read

----------------------------------------------------------------------------
## Computer Vision

|    | papers | code |
|:--:|:-------|:---:|
| ✅ | [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) | [github]() |
|  | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) | [github]() |
|  | [Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection](https://arxiv.org/abs/2205.09613) | [github]() |
|  | [HiViT: Hierarchical Vision Transformer Meets Masked Image Modeling](https://arxiv.org/abs/2205.14949) | [github]() |
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### Classification

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### HBB Object Detection

|    | papers | code |
|:--:|:-------|:---:|
| ✅ | [YOLOv10: Real-Time End-to-End Object Detection](https://arxiv.org/abs/2405.14458) | [github](https://github.com/THU-MIG/yolov10) |
|  | [DETRs Beat YOLOs on Real-time Object Detection](https://arxiv.org/abs/2304.08069) | [github](https://github.com/lyuwenyu/RT-DETR) |
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### OBB Object Detection

|    | papers | code |
|:--:|:-------|:---:|
|  | [Spatial Transform Decoupling for Oriented Object Detection](https://arxiv.org/html/2308.10561v2) | [github]() |
|  |  | [github]() |
|  |  | [github]() |


#### Semantic Segmentation

|    | papers | code |
|:--:|:-------|:---:|
|  | [Open-World Semantic Segmentation Including Class Similarity](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/sodano2024cvpr.pdf) | [github]() |
|  |  | [github]() |
|  |  | [github]() |

#### Instance Segmentation

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Language Model

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Multi-Modal

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Transfer Learning

|    | papers | code |
|:--:|:-------|:---:|
|  |  | [github]() |
|  |  | [github]() |
|  |  | [github]() |

----------------------------------------------------------------------------
## Multi-modal

|    | papers | code |
|:--:|:-------|:---:|
| ✅ | [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) | [github]() |
|  |  | [github]() |
|  |  | [github]() |


 
## Transformer
|    | papers | code |
|:--:|:-------|:---:|
|  | [DIFFERENTIAL TRANSFORMER](https://arxiv.org/pdf/2410.05258) | [github]() |
|  | [SELECTIVE ATTENTION IMPROVES TRANSFORMER](https://arxiv.org/pdf/2410.02703v1) | [github]() |
|  |  | [github]() |
