---
layout: post
title: RVT2
category: Reinforcement Learning
tag: [act]
---

# [RVT-2: Learning Precise Manipulation from Few Demonstrations](https://arxiv.org/pdf/2406.08545)


- solve multiple 3D manipulation tasks given language instructions. 

- from few demonstrations and solving them precisely. 

- Prior works, like PerAct [40] and RVT [17], have studied this problem, however, they often struggle with tasks requiring high precision.

- Using a combination of architectural and system-level improvements, we propose RVT-2, a multitask 3D manipulation model that is 6X faster in training and 2X faster in inference than its predecessor RVT. 


## Intro.
Similar examples can be found
in other domains like household and retail. In this work, we
study the problem of building a manipulation system that can
solve various tasks precisely, given just a few demonstrations.
The systems should have three key characteristics: (1) handle
multiple tasks, (2) require only a few demonstrations, and (3)
solve tasks with high precision.
Prior work has made significant progress towards this
goal. Starting with works like Transporter Networks [52] and
IFOR [16] that studied planar pick-and-place tasks, recent
works have gone beyond the 2D plane and studied manipulation in 3D with a few examples [25]. Some notable
methods are PerAct [40] and RVT [17]. Given a language
instruction, PerAct [40] adopted a multi-task transformer
model for 3D manipulation by predicting the next keyframe
pose. Even though PerAct achieved impressive performance,
## References

- [RVT-2: Learning Precise Manipulation from Few Demonstrations](https://arxiv.org/pdf/2406.08545)

- https://robotic-view-transformer-2.github.io/.