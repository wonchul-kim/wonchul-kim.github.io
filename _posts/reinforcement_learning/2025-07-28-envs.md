---
layout: post
title: Envs
category: Reinforcement Learning
tag: [envs]
---

| **시뮬레이터 (설명)**                                                                                                          | **로봇팔 예시**                                         | **RL 알고리즘 적용 예**                                                                                                                   | **링크**                                                                                                     | **장점 / 단점**                                                                                                                           |
| :---------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------ |
| **Gazebo**<br>오픈소스 3D 로봇 시뮬레이터(ROS 통합). 다양한 물리엔진(Bullet, ODE 등) 지원.                                                     | UR5, PR2, Kinova Gen3 등(사용자 URDF 로드)               | ROS+Gazebo 기반 예: Kinova Gen3를 이용한 pick-and-place 시뮬레이션 사례. gym-gazebo 프레임워크로 강화학습(Gazebo-Gym) 가능.                                  | Gazebo 공식(IGNITION) 사이트·GitHub, [ROS Gazebo Gym](https://github.com/rickstaa/ros-gazebo-gym)               | **장점:** 현실적 환경 모델링, 다양한 센서 모델, ROS 에코시스템. **단점:** 설정 복잡·무거움, RL 환경 구축 필요(기본 제공 안됨).                                                   |
| **PyBullet**<br>Bullet 기반 물리엔진, Python 바인딩 공개. 실시간 충돌 및 동역학 시뮬레이션.                                                      | KUKA, Franka Panda, UR 시리즈 등(다양한 로봇 모델)            | OpenAI Gym 로봇 작업(FetchPickAndPlace 등) PyBullet 버전 구현 예. HER+DDPG 적용 실험(다중 목표 Pick\&Place) 보고. 시연 데이터 활용 가능(예시 구현 있음).              | [PyBullet 공식](https://pybullet.org/) / [Bullet SDK GitHub](https://github.com/bulletphysics/bullet3)       | **장점:** 무료·경량·Python 인터페이스, GPU 가속 지원, 빠른 프로토타이핑. **단점:** MuJoCo보다 물리 정확도 낮음, 감지기 모델 한계, 상용 엔진 대비 기능 제한.                              |
| **Gymnasium (MuJoCo)**<br>OpenAI Gym (Farama Foundation) 로봇환경. MuJoCo 물리엔진 기반. `FetchReach`, `PickAndPlace` 등 표준 과제 제공. | 7-DOF Fetch Mobile Manipulator(병렬 그리퍼)             | DDPG/TD3+HER로 FetchPickAndPlace 학습 (Sparse reward) 등. 시연 강화를 위한 Buffer 활용 사례(‘Exploration with Demonstrations’ 등)이 있다.             | [Gymnasium-Robotics 도큐먼트](https://robotics.farama.org/) (Fetch/Panda 등)                                    | **장점:** 표준화된 로봇 과제(Reach, Push, Slide, Pick\&Place 등), 커뮤니티 활용도 높음. **단점:** MuJoCo 엔진 설치 필요(현재 오픈소스지만), 학습 시 리워드 설계 민감, 비주얼 센서 지원 한정. |
| **robosuite**<br>MuJoCo 기반 모듈식 시뮬레이션 프레임워크. Stanford SVL 주도 개발. 다양한 벤치마크 환경 제공.                                         | Sawyer, Baxter, Franka Panda, Jaco 등(모듈러 로봇 구성 가능) | `Single-arm PickPlace`, `TwoArmLift` 등 과제 포함. Robomimic과 연계된 *인간 시연 수집/재생* 유틸리티 제공. DDPG, PPO 등 RL 적용 예시 다수 존재.                    | [robosuite GitHub](https://github.com/ARISE-Initiative/robosuite)  / [문서](https://robosuite.ai/)           | **장점:** 다양한 로봇·과제, 시각·깊이 카메라 지원, 텍스처·조명 등 고품질 렌더링. **단점:** MuJoCo 필요, 초기 설정·러닝 커브 있음.                                                 |
| **RLBench**<br>CoppeliaSim(V-REP) 기반 로봇 학습 벤치마크. 비전 기반 조작 과제 다수(100개 이상).                                               | 기본 Franka Panda arm(사용자 정의로 Jaco, Sawyer 등 교체 가능)  | 픽 앤 플레이스, 조립, 문열기 등 다양한 과제. 주로 Imitation Learning(시연)용으로 설계. 사전 수집된 *데모 데이터셋* 제공. RL 학습도 가능.                                       | [RLBench GitHub](https://github.com/stepjam/RLBench)                                                       | **장점:** 방대한 작업 및 인간 시연 데이터 제공, 높은 자유도 환경, CV/로봇 연구활동 지원. **단점:** CoppeliaSim 설치 부담, 무거운 리소스, 실시간 학습 속도 느림.                            |
| **Meta-World**<br>Meta/Multi-task RL 벤치마크(50개 조작 과제). Sawyer 7DOF 로봇(가상 시뮬레이션) 사용.                                      | Sawyer 7-DOF 조작 로봇                                 | “Pick-Place”, “Stacking”, “DrawerOpen” 등 다양한 잡기/조작. 멀티태스크 및 메타-RL 연구에 활용. 기존 과제에 DDPG+HER 적용 예. 시연 데이터 직접 제공하진 않으나, D4RL 등과 결합 가능. | [Meta-World GitHub](https://github.com/Farama-Foundation/Metaworld) / [문서](https://metaworld.farama.org/)  | **장점:** 작업 다양성(50개), Meta/Multi-RL 연구 벤치마크. **단점:** 특정 로봇(가상 Sawyer) 한정, MuJoCo 필요.                                                   |
