---
layout: post
title: SENet
category: Computer Vision
tag: [block, attention]
---

# [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507)

## Problem

보통의 Image를 input으로 하는 `CNN`은 feature map을 생성하고, 이는 3D로 구성되어 있지만 `Channel`을 기준점으로 해서 feature map의 전체의 중요도를 나타낼 수 있다. 

## Solution

`SENet`에서는 `CNN`으로부터 생성된 feature map을 `Channel`을 기준으로 각각의 2D feature map에 대한 평균을 계산하고, 다시 기존의 feature map에 곱함으로서 `Channel Attention`에 따른 중요도를 적용한다. 


### Squeeze

<img src='/assets/senet/squeeze.png'>

`Global Average Pooling`을 사용하여 기존의 3D feature map을 1x1xC의 dimension으로 압축한다. 

### Excitation

<img src='/assets/senet/excitation.png'>

<img src='/assets/senet/senet.png'>

위의 그림처럼 `FC` -> `ReLU` -> `FC` -> `Sigmod`를 attention score를 도출할 수 있도록 학습한다. 

## Implementation

```python
import torch.nn as nn

class SEBlock(nn.Module):
    def __init__(self, channel, r=16):
        super().__init__()

        self.squeeze = nn.AdaptiveAvgPool2d((1, 1))
        self.excitation = nn.Sequential(
            nn.Linear(channel, channel//r, bias=False),
            nn.ReLU(),
            nn.Linear(channel//r, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x): # x: bchw
        x = self.squeeze(x)
        x = x.view(x.size(0), -1)
        x = self.excitation(x)
        x = x.view(x.size(0), x.size(1), 1, 1)

        return x
```










