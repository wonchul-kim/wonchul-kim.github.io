---
layout: post
title: Tensorboard
category: Computer Vision
tag: [tensorboard]
---


### Activation 

### Histogram
<img src='/assets/computer_vision/tensorboard/activation_histogram.png'>

- x축: 모든 활성화 함수의 output에 대한 distribution 
- y축: step
- z축: 해당 활성화 함수의 output에 대한 갯수

#### Distribution
<img src='/assets/computer_vision/tensorboard/activation_distribution.png>

- x축: step
- y축: 모든 활성화 함수의 output에 대한 standard normal distribution


1. `Dead neurons`

- `ReLU`와 같은 비선형 활성화 함수에서 output이 0이하로 떨어지면 neuron은 활성화되지 않으며, 학습에 기여하지 않는다. 
    - 특정한 큰 비율의 neuron들이 지속적으로 0 또는 매우 작은 값을 출력한다면, 학습에 문제가 있음   

- 대다수의 neuron이 일정 범위 내에서 활성화되는 것이 이상적


2. `Gradient vanishing/explding`

- `Dead neuron`과 비슷한 개념으로 활성화 함수에서의 output이 매우 작은 경우를 의미

- 활성화 함수가 비교적 고르게 분포되어 있다면, 학습 중 gradient가 적절한 크기를 유지하며 모델의 각 layer가 학습에 잘 기여하고 있음을 의미

3. `Overfitting`

- **학습하는 활발히 되는 동안에** 특정한 활성화 함수의 패턴이 발견되거나 변화가 거의 없다면, 학습이 특정 데이터에 `overfitting`되고 있다고 볼 수 있음

- **학습하는 활발히 되는 와중에는** 다양한 데이터에 대해서 활성화 함수의 output 또한 다양하게 변화하며 분포가 고르게 나타나야 함


> 균형 잡힌 분포: 각 레이어의 활성화 값이 0 근처에 몰려 있지 않고 다양한 값에 걸쳐 고르게 분포되어 있다면, 이는 뉴런들이 학습 과정에서 충분히 활성화되고 있으며, 모델이 다양한 패턴을 학습하고 있음을 시사합니다.

> 활성화 값의 변화: 학습이 진행됨에 따라 활성화 값의 분포가 변화하며 안정화되는 모습을 보이면, 이는 모델이 점차 데이터에 적응하고 있음을 나타냅니다.

> 특정 패턴이 없음: 활성화 히스토그램에 특정한 값에만 몰려 있는 패턴이 없는 것이 좋습니다. 이는 네트워크의 뉴런들이 모두 특정 패턴에 종속되지 않고, 다양하게 활성화되며 학습에 기여하고 있음을 의미합니다.



활성화 히스토그램이 학습이 잘 진행되고 있는지 판단하는 것은 매우 중요합니다. 이를 이해하기 위해 단계별로 설명하고, 각 상황에서 활성화 히스토그램이 어떻게 나타나는지 설명하겠습니다.

1. 초기 단계 (초기화 직후)
설명: 학습을 시작하기 전 또는 초기 단계에서의 활성화 히스토그램은 아직 특정한 패턴이 나타나지 않을 수 있습니다. 이 시점에서는 각 레이어의 가중치가 랜덤으로 초기화되어 있기 때문에, 활성화 값이 다양한 범위에 걸쳐 무작위로 분포될 가능성이 큽니다.
히스토그램 모습: 가로축에 대해 비교적 고르게 퍼진 분포를 보일 수 있습니다. 세로축으로는 아직 큰 피크 없이 낮고 고르게 나타날 수 있습니다.
2. 초기 학습 단계
설명: 학습이 시작되면, 모델은 점차 데이터의 패턴을 학습하기 시작합니다. 이 단계에서 히스토그램은 특정한 활성화 값으로 수렴하기 시작할 수 있습니다. 예를 들어, ReLU 활성화 함수는 음수 값을 모두 0으로 만들기 때문에, 0에 가까운 값들이 많아지기 시작할 수 있습니다.
히스토그램 모습: 활성화 값이 특정 범위(예: 0 근처)에 많이 몰릴 수 있지만, 너무 극단적이지는 않음. 그러나 이 시점에서는 아직 고르게 분포되기보다는 특정 값에 모이는 경향이 시작될 수 있습니다.
3. 중간 학습 단계
설명: 모델이 학습을 진행하면서 활성화 값의 분포가 안정되기 시작합니다. 이때, 이상적인 경우라면 활성화 값이 너무 좁은 범위에 집중되지 않고, 다양한 값에 걸쳐 분포됩니다.
히스토그램 모습:
가로축: 다양한 활성화 값에 걸쳐 분포합니다. 예를 들어, 활성화 값이 특정한 범위(0.1 ~ 0.4) 사이에 골고루 퍼져있을 수 있습니다.
세로축: 특정 범위에서의 피크가 생길 수 있습니다. 이는 많은 뉴런이 해당 범위의 값을 갖고 있음을 의미합니다.
4. 학습이 잘 진행되는 상태
설명: 학습이 잘 진행되고 있을 때, 활성화 값의 분포는 특정 값에 치우치지 않고 비교적 고르게 분포되어 있어야 합니다. 특히, 죽은 뉴런이 많아지지 않도록 활성화 값이 0에 몰려있지 않도록 하는 것이 중요합니다.
히스토그램 모습:
가로축: 활성화 값이 0에 몰리지 않고, 적당한 범위에 걸쳐 분포됩니다. 이 범위가 넓고 고르게 분포된다면 학습이 잘 진행되고 있음을 나타낼 수 있습니다.
세로축: 특정 범위에서 큰 피크가 생기지 않고 여러 구간에 걸쳐 고르게 분포되어 있는 것이 이상적입니다. 이는 네트워크의 다양한 뉴런들이 서로 다른 입력에 대해 다양하게 반응하고 있음을 나타냅니다.
5. 학습이 잘못된 경우 (문제 상황)
설명: 학습 도중 문제가 발생할 수 있는 상황에서는 히스토그램에 몇 가지 비정상적인 패턴이 나타날 수 있습니다.
히스토그램 모습:
가로축: 활성화 값이 거의 0에 몰려 있는 경우. 이는 죽은 뉴런이 많이 발생했음을 시사합니다.
세로축: 특정 범위에 아주 높은 피크가 형성되어 있다면, 이는 그 범위에 많은 뉴런이 몰려 있고, 모델이 비효율적으로 학습되고 있음을 나타낼 수 있습니다.
요약
가로축 분포: 활성화 값이 특정 값에 몰리지 않고, 넓은 범위에 걸쳐 고르게 분포되는 것이 바람직합니다. 이는 모델이 다양하게 학습하고 있음을 나타냅니다.

세로축 분포: 세로축은 각 활성화 값에 해당하는 뉴런의 수를 나타냅니다. 특정 값에 뉴런이 몰리지 않고 여러 구간에 고르게 분포될수록 좋습니다.

학습이 잘 진행되고 있는 경우, 활성화 히스토그램은 가로축에 대해 고르게 분포된 값들(너무 0에 치우치지 않은)과 세로축에서 여러 범위에 고르게 분포된 뉴런들로 구성된 모습이 나타납니다. 이런 패턴은 뉴런들이 활성화되고 있고, 그라디언트 소실/폭발 문제 없이 모델이 다양한 패턴을 학습하고 있다는 신호입니다.