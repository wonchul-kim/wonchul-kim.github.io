---
layout: post
title: Out-of-distribution detection
category: Computer Vision
tag: anomaly detection
---

## out-of-distribution Detection

Anomaly detection은 in-distribution sample로부터 out-of-distribution sample을 걸러내는 작업.



out-of-distribution(OOD) Detection은 현재 보유하고 있는 in-distribution 데이터 셋을 이용하여 multi-class classification network를 학습시킨 뒤, test 단계에서 in-distribution test set은 정확하게 예측하고 out-of-distribution 데이터 셋은 걸러내는 것을 목표로 하고 있다고 말씀드렸습니다.

하지만 기존 classification network는 분류를 위해 feature extractor 마지막 부분에 softmax를 붙여서 사용하는데, softmax 계산 식이 exponential 함수를 이용하기 때문에 예측 확률이 거의 1에 근접하는 high-confidence 예측이 자주 관찰됩니다. in-distribution 데이터 셋을 정확하게 high-confidence로 예측하는 것은 큰 문제가 되지 않습니다. 다만 out-of-distribution 데이터 셋을 test 단계에 넣어주는 경우, 이상적인 결과는 어떠한 class로도 예측되지 않도록 각 class를 (1/class 개수) 확률로 uniform 하게 예측하는 것입니다. 하지만 대부분의 경우 out-of-distribution 데이터 셋을 test 단계에 넣어주면 high-confidence 예측이 관찰되기 때문에 단순한 방법으로는 걸러 내기 힘든 문제가 있습니다.


Classifier를 학습시킬 때 0~9에 속하지 않는 sample들을 모아서 Unknown 이라는 11번째 class로 가정하여 11-way classification으로 문제를 바꿔서 학습시키는 것을 가장 먼저 생각해볼 수 있습니다. 다만 이러한 경우 이미 학습된 망을 다시 학습하여야 하는 문제와, Unknown sample을 다양하게 취득하여야 하는 한계가 존재합니다.

이러한 문제점에 집중해서 Unknown class를 추가하는 단순한 방법 대신 보다 더 효율적이면서 효과적인 방법을 제시한 논문들을 시간 순으로 소개를 드리겠습니다.


* 참조 논문
    * [A Baseline for Detecting Misclassified and out-of-Distribution Examples in Neural Networks, 2017 ICLR](https://arxiv.org/pdf/1610.02136.pdf)
        * in-distribution으로 학습을 진행하고, 학습에서 사용하지 않은 in-distribution과 out-of-distribution을 모두 test로 활용
        * calssifier에서의 결과에서 maximum softmax probability가 정해진 threshold보다 크면 in-distribution, 작으면 out-of-distribution
        * 이 때, <U>`threshold`는 hypter-parameter로 작용</U>
    <br/>

    * [Enhancing The Reliability of out-of-distribution Image Detection in Neural Networks, 2018 ICLR](https://arxiv.org/pdf/1706.02690.pdf)
        * <U>이미 학습이 된 network에 어떠한 추가적인 학습이나 변경없이 out-of-distribution을 구분 가능</U>
        > softmax score에 대한 threshold로 anomaly detection을 하는 거면, 당연히 추가적인 학습이 없는 거 아닌가? 이게 장점이 되나?

        * in-distribution sample과 out-of-distribution sample을 구분하는 방법은 classifier에서의 maximum softmax probability에 대한 threshold를 적용
        * 이 때, in-distribution sample과 out-of-distribution sample의 결과를 더 멀어지도록 하기 위해서 다음의 2 가지를 적용
            * Temperature scaling
                * 학습 중에는 &T = 1&이고, test에서는 1이 아닌 다른 수치로 하여 각 logit값을 나누어 줌으로써 in-distribution sample과 out-of-distribution sample의 softmax score를 멀어지게 하여 구분이 잘 되도록 가능
                * 이 때, <U>`T`는 hypter-parameter로 작용</U>

                * 참조 논문
                    * [Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531.pdf)에서 제안함
                    * [On Calibration of Modern Neural Networks](https://arxiv.org/pdf/1706.04599.pdf)에서도 적용함

            * Input preprocessing
                * 참조 논문
                    * [EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES](https://arxiv.org/pdf/1412.6572.pdf)에서 제안함
                        * backpropagation을 통해서 loss를 증가시키는 gradient를 계산하여 얻은 값을 input에 pertubation으로 더해줌으로써 true label에 대한 softmax score를 낮추어주는 방법을 적용

                * 위의 논문에서 제시한 바와 반대로 pertubation을 input에서 빼줌으로써 in-distribution sample에 대한 softmax score를 더 높임으로써 out-of-distribution sample과 더 구분이 가능해지도록 함
                * 이 때, <U>`pertubation maganitude parameter epsilon`이 hypter-parameter로 작용</U> 
        * <U>앞선 baseline 논문에 비해 큰 성능 향상을 보임</U>

    <br/>

    * [Training Confidence-calibrated Classifiers for Detecting out-of-Distribution Samples, 2018 ICLR](https://arxiv.org/pdf/1610.02136.pdf)
        * confidence loss 
            * out-of-distribution sample에 대한 distribution을 uniform distribution과 같아지도록 하기 위해서 KL-divergence를 기존의 loss fuction인 entropy loss에 추가
            > 이는 out-of-distribution sample에 대한 결과를 덜 confident 하도록 ???

        * in-distribution sample 근처의 out-of-distribution sample을 이용하여 decision boundary를 더 강화
            * 이 때, 해당하는 out-of-distribution sample은 취득하기 힘들기 때문에 본 논문에서는 GAN으로 생성
            > 해당하는 out-of-distribution sample을 생성해서 데이터 셋을 따로 구축? 또는 GAN loss만 활용하여서도 가능?


        * 위의 2가지에 대한 방법을 모두 활용하여야지만 성능이 향상되고, 단순히 confidence loss만 활용하면 성능이 저하됨,,;;
        > 음,,,,

    <br/>

    * [A Simple Unified Framework for Detecting out-of-Distribution Samples and Adversarial Attacks, 2018 NIPS](https://proceedings.neurips.cc/paper/2018/file/abdeb6f575ac5c6676b747bca8d09cc2-Paper.pdf)
        * 위의 논무에 대한 후속논문으로 이미 학습이 끝난 network의 feature들은 class-conditional gaussian distribution을 따른 다는 가정하에 가장 가까운 class-conditional distribution에 대한 mahalanobis distance를 구하여 confidence loss로 사용함
        * 


    <br/>

    * [Deep Anomaly Detection with Outlier Exposure, 2019 ICLR](https://openreview.net/pdf?id=HyxCxhRcY7)

    <br/>


    ### References
    1. https://hoya012.github.io/blog/anomaly-detection-overview-2/