---
layout: post
title: Dinov2 Embeddings
category: Computer Vision
tag: [dinov2, embedding]
---


# Embeddings from Foundation Models

## Dinov2

#### Embedding ì¢…ë¥˜

| ì¢…ë¥˜                                    | ì„¤ëª…                                                      | ì£¼ìš” ìš©ë„                                          |
| ------------------------------------- | ------------------------------------------------------- | ---------------------------------------------- |
| **\[CLS] Token Embedding**            | ì…ë ¥ ì´ë¯¸ì§€ ì „ì²´ë¥¼ ìš”ì•½í•˜ëŠ” 1ê°œì˜ ë²¡í„° (`[CLS]`)                        | ğŸ”¹ classification, zero-shot transfer, retrieval                                      |
| **Patch Embeddings**                  | ì´ë¯¸ì§€ê°€ patch ë‹¨ìœ„ë¡œ ë¶„í• ë˜ì–´ ê° patchì— ëŒ€í•´ ë…ë¦½ì ì¸ ì„ë² ë”© ì œê³µ             | ğŸ”¹ Dense prediction (e.g., segmentation), attention map       |
| **Last Hidden State**                 | ëª¨ë“  í† í°(`N` patches + 1 `[CLS]`)ì— ëŒ€í•œ ë§ˆì§€ë§‰ ë ˆì´ì–´ ì„ë² ë”©          | ğŸ”¹ ë‹¤ì–‘í•œ downstream taskì˜ feature ì…ë ¥             |
| **Intermediate Layer Embeddings**     | ë§ˆì§€ë§‰ ë ˆì´ì–´ê°€ ì•„ë‹Œ ì¤‘ê°„ layerì—ì„œì˜ í‘œí˜„                              | ğŸ”¹ ì‹œê°ì  feature í•´ì„, multi-layer feature                              |
| **Projected Embedding (head output)** | linear or MLP headë¥¼ í†µê³¼í•œ ì„ë² ë”© (ì„ íƒì )                       | ğŸ”¹ supervised fine-tuning, classification head |
| **Student vs. Teacher Embeddings**    | DINO êµ¬ì¡° íŠ¹ì„±ìƒ teacherì™€ studentê°€ ìˆìŒ â†’ ë‘ ë„¤íŠ¸ì›Œí¬ì˜ ì„ë² ë”© ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥ | ğŸ”¹ knowledge distillation, representation stability                      |


### Embedding dimension

| ëª¨ë¸              | \[CLS] ì°¨ì› | patch ê°œìˆ˜    | patch embedding ì°¨ì› |
| --------------- | --------- | ----------- | ------------------ |
| DINOv2-ViT-S/14 | 384       | 14Ã—14 = 196 | 384                |
| DINOv2-ViT-B/14 | 768       | 196         | 768                |
| DINOv2-ViT-L/14 | 1024      | 196         | 1024               |
| DINOv2-ViT-G/14 | 1536      | 196         | 1536               |

### How to get embedding

#### `facebookresearch/dinov2`


* ëª¨ë¸ ìš”ì•½ë„ 
    ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Input Image  â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Patch Embedding    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Transformer Blocks â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
            [CLS] + Patch
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ x_prenorm    â”‚ â† LayerNorm ì „ ì „ì²´
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ LayerNorm          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ x_norm_cls   â”‚ x_norm_patch â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```


* `outputs` (`dict`)
    ```python
        outputs = model.forward_features(input_tensor)
    ```


    | key                               | ì„¤ëª…                                     | LayerNorm ì—¬ë¶€ | ëŒ€í‘œ ì‚¬ìš© ëª©ì                              | ì‚¬ìš© ì˜ˆì‹œ                  |
    | ------------------------------- | -------------------------------------- | ------------ | ------------------------------------ | ---------------------- |
    | **`x_norm_clstoken`**           | `[CLS]` token (LayerNorm ì´í›„)           | âœ… ìˆìŒ         | **ì´ë¯¸ì§€ ì „ì²´ ìš”ì•½** í‘œí˜„                     | ğŸ”¹ classification, retrieval, clustering, clip-like VLMs      |
    | **`x_norm_patchtokens`**        | ëª¨ë“  patch token (LayerNorm ì´í›„)          | âœ… ìˆìŒ         | **Dense feature map**                | ğŸ”¹ segmentation, detection, captioning (VLMs)        |
    | **`x_prenorm`**                 | `[CLS] + patch tokens`, LayerNorm ì ìš© ì „ | âŒ ì—†ìŒ         | **Transformer ë‚´ë¶€ (raw output) ë¶„ì„**, | ğŸ”¹ attention weight ë¶„ì„, residual connection, intermediate feat. |
    | **`masks`**                     | masking ì—¬ë¶€ í‘œì‹œ (í•™ìŠµ ì‹œ ì‚¬ìš©)                | â€”            | **masked autoencoding í•™ìŠµìš©**          | ğŸ”¹ DINOv2 pretraining, maskd fine-tuning  |


    * `x_norm_clstoken`: (bs, emb_size)
    * `x_norm_patchtoken`: (bs, num_patch, emb_size)
    * `x_prenorm`: (bs, num_patch + 1, emb_size)
    * `masks`: (bs, emb_size)

* **mask-aware forward pass**

    | ìš©ë„                             | ì„¤ëª…                                   |
    | ------------------------------ | ------------------------------------ |
    | Pre-training (self-supervised) | ì¼ë¶€ patchë¥¼ maskí•˜ê³ , ë‚˜ë¨¸ì§€ë¡œ ê·¸ê±¸ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµ   |
    | Fine-tuningì—ì„œ ì¼ë¶€ ì˜ì—­ ë¬´ì‹œ         | íŠ¹ì • ì˜ì—­ì„ dropout/maskí•˜ì—¬ regularization |
    | Dense prediction í•™ìŠµ            | íŠ¹ì • ìœ„ì¹˜ë¥¼ ì˜ë„ì ìœ¼ë¡œ ë¬´ì‹œí•˜ê±°ë‚˜ maskingí•´ì„œ í•™ìŠµ ì•ˆì •í™”  |


    ```python
        def forward_features(self, x, masks=None):
            if isinstance(x, list):
                return self.forward_features_list(x, masks)

            x = self.prepare_tokens_with_masks(x, masks)

            for blk in self.blocks:
                x = blk(x)

            x_norm = self.norm(x)
            return {
                "x_norm_clstoken": x_norm[:, 0],
                "x_norm_regtokens": x_norm[:, 1 : self.num_register_tokens + 1],
                "x_norm_patchtokens": x_norm[:, self.num_register_tokens + 1 :],
                "x_prenorm": x,
                "masks": masks,
            }
    ```

    ```python
        def prepare_tokens_with_masks(self, x, masks=None):
        B, nc, w, h = x.shape
        x = self.patch_embed(x) # x: (bs, num_patches, emb_size)
        if masks is not None:
            # self.mask_token: zeros of (bs, emb_size)
            x = torch.where(masks.unsqueeze(-1), self.mask_token.to(x.dtype).unsqueeze(0), x)

        x = torch.cat((self.cls_token.expand(x.shape[0], -1, -1), x), dim=1)
        x = x + self.interpolate_pos_encoding(x, w, h)

        if self.register_tokens is not None:
            x = torch.cat(
                (
                    x[:, :1],
                    self.register_tokens.expand(x.shape[0], -1, -1),
                    x[:, 1:],
                ),
                dim=1,
            )

        return x
    ```

    * `masks`ëŠ” **patch-level mask** ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” `(B, N) shaped boolean tensor`ì…ë‹ˆë‹¤.

        * `x = torch.where(masks.unsqueeze(-1), self.mask_token.to(x.dtype).unsqueeze(0), x)`
            ```python
                x = torch.where(
                    masks.unsqueeze(-1),                   # shape: (B, N, 1)
                    self.mask_token.unsqueeze(0),         # shape: (1, 1, D) â† broadcast ë¨
                    x                                      # shape: (B, N, D)
                )
            ```

        * `x`ëŠ” `mask`ëœ ìœ„ì¹˜ëŠ” `mask_token`ì´ ì ìš©ë˜ê³ , ì•„ë‹Œ ê³³ì€ ì›ë˜ì˜ `patch`ê°’ì´ ì ìš©ë¨



    * ì´ êµ¬ì¡°ëŠ” BERT-style maskingê³¼ ìœ ì‚¬í•˜ê²Œ ì‘ë™í•˜ì—¬ self-supervised pretrainingì˜ í•µì‹¬ ì—­í• 


* `Resister token`

    ```txt
    [CLS] + [REG_1] + [REG_2] + ... + [REG_K] + patch_1 + patch_2 + ...
    ```
    * ìœ„ì™€ ê°™ì´ embeddingì— í¬í•¨ë˜ê³ , í•™ìŠµ ê°€ëŠ¥í•œ tokenì„ (`nn.Parameter`)
    * `num_register_tokens`ë¡œ ì§€ì •

    | ëª©ì                        | ì„¤ëª…                                  | ì‚¬ìš© ì˜ˆì‹œ                                          |
    | ------------------------ | ----------------------------------- | ---------------------------------------------- |
    | **Feature collector**    | Patchë“¤ì´ ê°€ì§„ ì •ë³´ë¥¼ "ë°›ì•„ë“¤ì´ëŠ” ì¤‘ê°„ í† í°" ì—­í•      | Slot Attention (object-centric), DINOv1-early  |
    | **Auxiliary task**       | Reg tokenì— MLP headë¥¼ ë¶™ì—¬ì„œ ë³„ë„ loss í•™ìŠµ | e.g., color prediction, contrastive loss       |
    | **Prompt-like role**     | íŠ¹ì • taskì— íŠ¹í™”ëœ instruction ì—­í•          | Meta-Learning, Prompt Tuning                   |
    | **Knowledge bottleneck** | ì—¬ëŸ¬ í† í°ì˜ ì •ë³´ë¥¼ **ì••ì¶•í•´ì„œ ì •ë¦¬**              | Object-centric learning, causal token learning |


    * ì‹¤ì œ ì‚¬ìš© ì˜ˆ: Slot Attention (Locatello et al., 2020)

        * ì´ˆê¸° slot token (reg) ë“¤ì„ transformerì— ë„£ìŒ

        * ì´ tokenë“¤ì´ ì „ì²´ ì´ë¯¸ì§€ì˜ ì—¬ëŸ¬ objectì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ "ë°›ì•„ë“¤ì„"

        * ì´í›„ ì´ tokenë“¤ë§Œ decoding

        * DINOv2ì—ì„œ ìœ ì‚¬í•œ ê±¸ í•˜ë ¤ë©´ reg_tokenì— headë¥¼ ë¶™ì—¬ì„œ ì´ë ‡ê²Œ ì‚¬ìš©:
            ```python
                x = model.forward_features(x)
                reg_feat = x["x_norm_regtokens"]  # shape: (B, K, D)
                logits = MLP_head(reg_feat)       # auxiliary head
                loss = auxiliary_loss(logits)
            ```

    * í•˜ì§€ë§Œ, **Dinov2**ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
